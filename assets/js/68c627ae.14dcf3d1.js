"use strict";(self.webpackChunkdocu=self.webpackChunkdocu||[]).push([[99006],{99523:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>o,default:()=>m,frontMatter:()=>i,metadata:()=>s,toc:()=>l});var a=n(87462),r=(n(67294),n(3905));const i={},o="Incremental Syncs",s={unversionedId:"connector-development/config-based/understanding-the-yaml-file/incremental-syncs",id:"connector-development/config-based/understanding-the-yaml-file/incremental-syncs",title:"Incremental Syncs",description:"An incremental sync is a sync which pulls only the data that has changed since the previous sync (as opposed to all the data available in the data source).",source:"@site/../docs/connector-development/config-based/understanding-the-yaml-file/incremental-syncs.md",sourceDirName:"connector-development/config-based/understanding-the-yaml-file",slug:"/connector-development/config-based/understanding-the-yaml-file/incremental-syncs",permalink:"/connector-development/config-based/understanding-the-yaml-file/incremental-syncs",draft:!1,editUrl:"https://github.com/airbytehq/airbyte/blob/master/docs/../docs/connector-development/config-based/understanding-the-yaml-file/incremental-syncs.md",tags:[],version:"current",frontMatter:{},sidebar:"mySidebar",previous:{title:"Error handling",permalink:"/connector-development/config-based/understanding-the-yaml-file/error-handling"},next:{title:"Pagination",permalink:"/connector-development/config-based/understanding-the-yaml-file/pagination"}},d={},l=[{value:"DatetimeBasedCursor",id:"datetimebasedcursor",level:2},{value:"Lookback Windows",id:"lookback-windows",level:3},{value:"Filtering according to Cursor Field",id:"filtering-according-to-cursor-field",level:3},{value:"More readings",id:"more-readings",level:2}],p={toc:l},c="wrapper";function m(e){let{components:t,...n}=e;return(0,r.kt)(c,(0,a.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"incremental-syncs"},"Incremental Syncs"),(0,r.kt)("p",null,"An incremental sync is a sync which pulls only the data that has changed since the previous sync (as opposed to all the data available in the data source)."),(0,r.kt)("p",null,"Incremental syncs are usually implemented using a cursor value (like a timestamp) that delineates which data was pulled and which data is new. A very common cursor value is an ",(0,r.kt)("inlineCode",{parentName:"p"},"updated_at")," timestamp. This cursor means that records whose ",(0,r.kt)("inlineCode",{parentName:"p"},"updated_at")," value is less than or equal than that cursor value have been synced already, and that the next sync should only export records whose ",(0,r.kt)("inlineCode",{parentName:"p"},"updated_at")," value is greater than the cursor value."),(0,r.kt)("p",null,"On a stream, ",(0,r.kt)("inlineCode",{parentName:"p"},"incremental_sync")," defines the connector behavior to support cursor based replication."),(0,r.kt)("p",null,"When a stream is read incrementally, a state message will be output by the connector after reading all the records, which allows for checkpointing (link: ",(0,r.kt)("a",{parentName:"p",href:"https://docs.airbyte.com/understanding-airbyte/airbyte-protocol/#state--checkpointing"},"https://docs.airbyte.com/understanding-airbyte/airbyte-protocol/#state--checkpointing"),"). On the next incremental sync, the prior state message will be used to determine the next set of records to read."),(0,r.kt)("h2",{id:"datetimebasedcursor"},"DatetimeBasedCursor"),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"DatetimeBasedCursor")," is used to read records from the underlying data source (e.g: an API)  according to a specified datetime range. This time range is partitioned into time windows according to the ",(0,r.kt)("inlineCode",{parentName:"p"},"step"),". For example, if you have ",(0,r.kt)("inlineCode",{parentName:"p"},"start_time=2022-01-01T00:00:00"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"end_time=2022-01-05T00:00:00")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"step=P1D"),", the following partitions will be created:"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Start"),(0,r.kt)("th",{parentName:"tr",align:null},"End"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"2022-01-01T00:00:00"),(0,r.kt)("td",{parentName:"tr",align:null},"2022-01-01T23:59:59")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"2022-01-02T00:00:00"),(0,r.kt)("td",{parentName:"tr",align:null},"2022-01-02T23:59:59")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"2022-01-03T00:00:00"),(0,r.kt)("td",{parentName:"tr",align:null},"2022-01-03T23:59:59")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"2022-01-04T00:00:00"),(0,r.kt)("td",{parentName:"tr",align:null},"2022-01-04T23:59:59")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"2022-01-05T00:00:00"),(0,r.kt)("td",{parentName:"tr",align:null},"2022-01-05T00:00:00")))),(0,r.kt)("p",null,"During the sync, records are read from the API according to these time windows and the ",(0,r.kt)("inlineCode",{parentName:"p"},"cursor_field")," indicates where the datetime value is stored on a record. This cursor is progressed as these partitions of records are successfully transmitted to the destination."),(0,r.kt)("p",null,"Upon a successful sync, the final stream state will be the datetime of the last record emitted. On the subsequent sync, the connector will fetch records whose cursor value begins on that datetime and onward."),(0,r.kt)("p",null,"Schema:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'  DatetimeBasedCursor:\n    description: Cursor to provide incremental capabilities over datetime\n    type: object\n    required:\n      - type\n      - cursor_field\n      - end_datetime\n      - datetime_format\n      - cursor_granularity\n      - start_datetime\n      - step\n    properties:\n      type:\n        type: string\n        enum: [DatetimeBasedCursor]\n      cursor_field:\n        description: The location of the value on a record that will be used as a bookmark during sync\n        type: string\n      datetime_format:\n        description: The format of the datetime\n        type: string\n      cursor_granularity:\n        description: Smallest increment the datetime_format has (ISO 8601 duration) that is used to ensure the start of a slice does not overlap with the end of the previous one\n        type: string\n      end_datetime:\n        description: The datetime that determines the last record that should be synced\n        anyOf:\n          - type: string\n          - "$ref": "#/definitions/MinMaxDatetime"\n      start_datetime:\n        description: The datetime that determines the earliest record that should be synced\n        anyOf:\n          - type: string\n          - "$ref": "#/definitions/MinMaxDatetime"\n      step:\n        description: The size of the time window (ISO8601 duration)\n        type: string\n      end_time_option:\n        description: Request option for end time\n        "$ref": "#/definitions/RequestOption"\n      lookback_window:\n        description: How many days before start_datetime to read data for (ISO8601 duration)\n        type: string\n      start_time_option:\n        description: Request option for start time\n        "$ref": "#/definitions/RequestOption"\n      partition_field_end:\n        description: Partition start time field\n        type: string\n      partition_field_start:\n        description: Partition end time field\n        type: string\n      $parameters:\n        type: object\n        additionalProperties: true\n  MinMaxDatetime:\n    description: Compares the provided date against optional minimum or maximum times. The max_datetime serves as the ceiling and will be returned when datetime exceeds it. The min_datetime serves as the floor\n    type: object\n    required:\n      - type\n      - datetime\n    properties:\n      type:\n        type: string\n        enum: [MinMaxDatetime]\n      datetime:\n        type: string\n      datetime_format:\n        type: string\n        default: ""\n      max_datetime:\n        type: string\n      min_datetime:\n        type: string\n      $parameters:\n        type: object\n        additionalProperties: true\n')),(0,r.kt)("p",null,"Example:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'incremental_sync:\n  type: DatetimeBasedCursor\n  start_datetime: "2022-01-01T00:00:00.000000+0000"\n  end_datetime: "2022-01-05T00:00:00.000000+0000"\n  datetime_format: "%Y-%m-%dT%H:%M:%S.%f%z"\n  cursor_granularity: "PT0.000001S"\n  step: "P1D"\n')),(0,r.kt)("p",null,"will result in the datetime partition windows in the example mentioned earlier."),(0,r.kt)("h3",{id:"lookback-windows"},"Lookback Windows"),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"DatetimeBasedCursor")," also supports an optional lookback window, specifying how many days before the start_datetime to read data for."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'incremental_sync:\n  type: DatetimeBasedCursor\n  start_datetime: "2022-02-01T00:00:00.000000+0000"\n  end_datetime: "2022-03-01T00:00:00.000000+0000"\n  datetime_format: "%Y-%m-%dT%H:%M:%S.%f%z"\n  cursor_granularity: "PT0.000001S"\n  lookback_window: "P31D"\n  step: "P1D"\n')),(0,r.kt)("p",null,"will read data from ",(0,r.kt)("inlineCode",{parentName:"p"},"2022-01-01")," to ",(0,r.kt)("inlineCode",{parentName:"p"},"2022-03-01"),"."),(0,r.kt)("p",null,"The stream partitions will be of the form ",(0,r.kt)("inlineCode",{parentName:"p"},'{"start_date": "2021-02-01T00:00:00.000000+0000", "end_date": "2021-02-02T23:59:59.999999+0000"}'),"\nThe stream partitions' field names can be customized through the ",(0,r.kt)("inlineCode",{parentName:"p"},"partition_field_start")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"partition_field_end")," parameters."),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"datetime_format")," can be used to specify the format of the start and end time. It is ",(0,r.kt)("a",{parentName:"p",href:"https://datatracker.ietf.org/doc/html/rfc3339#section-5.6"},"RFC3339")," by default."),(0,r.kt)("p",null,"The Stream's state will be derived by reading the record's ",(0,r.kt)("inlineCode",{parentName:"p"},"cursor_field"),".\nIf the ",(0,r.kt)("inlineCode",{parentName:"p"},"cursor_field")," is ",(0,r.kt)("inlineCode",{parentName:"p"},"updated_at"),", and the record is ",(0,r.kt)("inlineCode",{parentName:"p"},'{"id": 1234, "created": "2021-02-02T00:00:00.000000+0000"}'),", then the state after reading that record is ",(0,r.kt)("inlineCode",{parentName:"p"},'"updated_at": "2021-02-02T00:00:00.000000+0000"'),". ",(0,r.kt)("sup",{parentName:"p",id:"fnref-1"},(0,r.kt)("a",{parentName:"sup",href:"#fn-1",className:"footnote-ref"},"1"))),(0,r.kt)("p",null,"Note that all durations are expressed as ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/ISO_8601#Durations"},"ISO 8601 durations"),"."),(0,r.kt)("h3",{id:"filtering-according-to-cursor-field"},"Filtering according to Cursor Field"),(0,r.kt)("p",null,"If an API supports filtering data based on the cursor field, the ",(0,r.kt)("inlineCode",{parentName:"p"},"start_time_option")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"end_time_option")," parameters can be used to configure this filtering.\nFor instance, if the API supports filtering using the request parameters ",(0,r.kt)("inlineCode",{parentName:"p"},"created[gte]")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"created[lte]"),", then the component can specify the request parameters as"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'incremental_sync:\n  type: DatetimeBasedCursor\n  <...>\n  start_time_option:\n    type: RequestOption\n    field_name: "created[gte]"\n    inject_into: "request_parameter"\n  end_time_option:\n    type: RequestOption\n    field_name: "created[lte]"\n    inject_into: "request_parameter"\n')),(0,r.kt)("h2",{id:"more-readings"},"More readings"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"/connector-development/cdk-python/incremental-stream"},"Incremental reads"))))}m.isMDXComponent=!0},3905:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>h});var a=n(67294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var d=a.createContext({}),l=function(e){var t=a.useContext(d),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},p=function(e){var t=l(e.components);return a.createElement(d.Provider,{value:t},e.children)},c="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},u=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,i=e.originalType,d=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),c=l(n),u=r,h=c["".concat(d,".").concat(u)]||c[u]||m[u]||i;return n?a.createElement(h,o(o({ref:t},p),{},{components:n})):a.createElement(h,o({ref:t},p))}));function h(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=n.length,o=new Array(i);o[0]=u;var s={};for(var d in t)hasOwnProperty.call(t,d)&&(s[d]=t[d]);s.originalType=e,s[c]="string"==typeof e?e:r,o[1]=s;for(var l=2;l<i;l++)o[l]=n[l];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}u.displayName="MDXCreateElement"}}]);